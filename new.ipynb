{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Даниил\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from prettytable import PrettyTable\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "max_length = 512 # truncate output to this predefined length \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "seed = 42\n",
    "\n",
    "def randomize_model(model):\n",
    "    for module_ in model.named_modules(): \n",
    "        if isinstance(module_[1],(torch.nn.Linear, torch.nn.Embedding)):\n",
    "            module_[1].weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n",
    "        elif isinstance(module_[1], torch.nn.LayerNorm):\n",
    "            module_[1].bias.data.zero_()\n",
    "            module_[1].weight.data.fill_(1.0)\n",
    "        if isinstance(module_[1], torch.nn.Linear) and module_[1].bias is not None:\n",
    "            module_[1].bias.data.zero_()\n",
    "    return model\n",
    "\n",
    "class EncoderForSequenceClassification(nn.Module):\n",
    "    def __init__(self, model_name, classes, pretrained=True) -> None:\n",
    "        super(EncoderForSequenceClassification, self).__init__()\n",
    "\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        if not pretrained:\n",
    "            self.encoder = randomize_model(self.encoder)\n",
    "\n",
    "        self.name = model_name + ' for Sequence Classification'\n",
    "        self.task = 'classification'\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(self.encoder.config.hidden_size, classes)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.encoder(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        pooled_output = self.dropout(outputs[1])\n",
    "        predicts = self.classifier(pooled_output)\n",
    "        predicts = nn.Softmax(dim=-1)(predicts)\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        return {\n",
    "            'predicts': predicts,\n",
    "            'loss': loss_fn(predicts, labels) if labels is not None else None\n",
    "        }\n",
    "\n",
    "class EncoderForTokenClassification(nn.Module):\n",
    "    def __init__(self, model_name, classes, pretrained=True) -> None:\n",
    "        super(EncoderForTokenClassification, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        if not pretrained:\n",
    "            self.encoder = randomize_model(self.encoder)\n",
    "\n",
    "        self.name = model_name + ' for Token Classification'\n",
    "        self.task = 'ner'\n",
    "\n",
    "        self.classes = classes\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(self.encoder.config.hidden_size, classes)\n",
    "    \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.encoder(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        logits = self.classifier(self.dropout(outputs[0]))\n",
    "        predicts = nn.Softmax(dim=-1)(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            seq_loss = loss_fn(logits.permute(0, 2, 1), labels)\n",
    "            label_mask = attention_mask[:, 1:].float()\n",
    "            loss = ((seq_loss * label_mask).sum()) / label_mask.sum()\n",
    "        return {\n",
    "            'labels': labels,\n",
    "            'outputs': outputs[0],\n",
    "            'predicts': predicts,\n",
    "            'loss': loss\n",
    "        }\n",
    "\n",
    "class EncoderForQuestionAnswering(nn.Module):\n",
    "    def __init__(self, model_name, labels, pretrained=True) -> None:\n",
    "        super(EncoderForQuestionAnswering, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        if not pretrained:\n",
    "            self.encoder = randomize_model(self.encoder)\n",
    "\n",
    "        self.name = model_name + ' for Question Answering'\n",
    "        self.task = 'qa'\n",
    "\n",
    "        self.labels = labels\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(self.encoder.config.hidden_size, labels)\n",
    "    \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.encoder(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        logits = self.qa_outputs(self.dropout(outputs[0]))\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        outputs = (start_logits, end_logits,) + outputs[2:]\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions.clamp_(0, ignored_index)\n",
    "            end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "\n",
    "        return {\n",
    "            'predicts': (start_logits, end_logits),\n",
    "            'loss': total_loss\n",
    "        }\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def loadIMDB(tokenizer, slice=100):\n",
    "    raw_train, raw_test = load_dataset(\n",
    "        'imdb', \n",
    "        split=[f'train[:{slice}%]', f'test[:{slice}%]']\n",
    "    )\n",
    "    \n",
    "    def tokenize(examples):\n",
    "        return tokenizer(examples['text'], return_tensors='pt', padding='max_length', max_length=max_length, truncation=True)\n",
    "    \n",
    "    full_train_set = raw_train.map(tokenize, batched=True).shuffle(seed=seed)\n",
    "    \n",
    "    train_size = int(raw_train.num_rows * 0.9)\n",
    "    train_set = full_train_set.select(range(train_size))\n",
    "    val_set = full_train_set.select(range(train_size, full_train_set.num_rows))\n",
    "    test_set = raw_test.map(tokenize, batched=True).shuffle(seed=seed)\n",
    "\n",
    "    train_set = train_set.remove_columns(['text']).rename_column('label', 'labels')\n",
    "    val_set = val_set.remove_columns(['text']).rename_column('label', 'labels')\n",
    "    test_set = test_set.remove_columns(['text']).rename_column('label', 'labels')\n",
    "\n",
    "    train_set.set_format('torch')\n",
    "    val_set.set_format('torch')\n",
    "    test_set.set_format('torch')\n",
    "    \n",
    "    return {\n",
    "        'train': train_set, \n",
    "        'val': val_set, \n",
    "        'test': test_set\n",
    "    }\n",
    "\n",
    "def loadCONLL(tokenizer, slice=100):\n",
    "    raw_ner_train, raw_ner_val, raw_ner_test = load_dataset(\n",
    "    'conll2003',\n",
    "    split=[f'train[:{slice}%]', f'validation[:{slice}%]', f'test[:{slice}%]']\n",
    "    )\n",
    "\n",
    "    tags = raw_ner_train.features['ner_tags'].feature.names\n",
    "\n",
    "    def tokenize_and_align_labels(examples):\n",
    "        tokenized_inputs = tokenizer(examples[\"tokens\"], return_tensors='pt', padding='max_length', max_length=max_length, truncation=True, is_split_into_words=True)\n",
    "\n",
    "        labels = []\n",
    "        for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                    label_ids.append(label[word_idx])\n",
    "                else:\n",
    "                    label_ids.append(-100)\n",
    "                previous_word_idx = word_idx\n",
    "            labels.append(label_ids)\n",
    "\n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "        return tokenized_inputs\n",
    "\n",
    "    tokenized_ner_train = raw_ner_train.map(tokenize_and_align_labels, batched=True).remove_columns(['id', 'pos_tags', 'chunk_tags', 'ner_tags', 'tokens'])\n",
    "    tokenized_ner_val = raw_ner_val.map(tokenize_and_align_labels, batched=True).remove_columns(['id', 'pos_tags', 'chunk_tags', 'ner_tags', 'tokens'])\n",
    "    tokenized_ner_test = raw_ner_test.map(tokenize_and_align_labels, batched=True).remove_columns(['id', 'pos_tags', 'chunk_tags', 'ner_tags', 'tokens'])\n",
    "\n",
    "    tokenized_ner_train.set_format('torch')\n",
    "    tokenized_ner_val.set_format('torch')\n",
    "    tokenized_ner_test.set_format('torch')\n",
    "\n",
    "    return {\n",
    "        'train': tokenized_ner_train, \n",
    "        'val': tokenized_ner_val, \n",
    "        'test': tokenized_ner_test,\n",
    "        'tags': tags\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import collections\n",
    "import evaluate\n",
    "import logging\n",
    "import os\n",
    "\n",
    "''' MAIN VALIDATION FUNCTION'''\n",
    "def evalModel(model, set, tags, metric, step, writer=None):\n",
    "\n",
    "    predicted, true = [], []\n",
    "    val_loss = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm(set):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            labels = batch['labels']\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            vloss = outputs['loss'].item()\n",
    "            val_loss.append(vloss)\n",
    "        \n",
    "            predict = torch.argmax(outputs['predicts'], dim=-1)\n",
    "        \n",
    "            true.extend(labels.to('cpu'))\n",
    "            predicted.extend(predict.to('cpu'))\n",
    "\n",
    "    predicted, labels = torch.stack(predicted), torch.stack(true)\n",
    "\n",
    "    task = model.task\n",
    "\n",
    "    if task == 'classification':\n",
    "    \n",
    "        result = metric.compute(predictions=predicted, references=labels)\n",
    "        returned = (list(result.values()), np.mean(np.array(val_loss)))\n",
    "\n",
    "        if writer is not None:\n",
    "            logging.info(f'Evaluation result: {returned[0]}, loss: {returned[1]}')\n",
    "            writer.add_scalar('eval/loss', returned[1], step)\n",
    "            writer.add_scalar('eval/accuracy', returned[0][0], step)\n",
    "\n",
    "    if task == 'ner':\n",
    "\n",
    "        true_predictions = [\n",
    "            [tags[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predicted, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [tags[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predicted, labels)\n",
    "        ]\n",
    "\n",
    "        results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "        \n",
    "        metrics = {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }\n",
    "\n",
    "        loss = np.mean(np.array(val_loss))\n",
    "\n",
    "        if writer is not None:\n",
    "            logging.info(f'Evaluation result: {metrics.items()}, loss: {loss}')\n",
    "            writer.add_scalar('eval/loss', loss, step)\n",
    "            writer.add_scalar('eval/f1', metrics['f1'], step)\n",
    "            writer.add_scalar('eval/accuracy', metrics['accuracy'], step)\n",
    "            writer.add_scalar('eval/precision', metrics['precision'], step)\n",
    "            writer.add_scalar('eval/recall', metrics['recall'], step)\n",
    "        \n",
    "        else: print(metrics, loss)\n",
    "\n",
    "''' MAIN TRAINING FUNCTION '''\n",
    "def trainModel(\n",
    "    model,\n",
    "    run_name,\n",
    "    num_epochs,\n",
    "    train_dataset,\n",
    "    train_batch_size,\n",
    "    lr,\n",
    "    dataset_name='unknown',\n",
    "    lr_scheduler_type='linear',\n",
    "    log_steps=1,\n",
    "    optimizer=AdamW, \n",
    "    warmup_steps=0,\n",
    "    val_dataset=None,\n",
    "    val_batch_size=1,\n",
    "    val_strategy='epoch',\n",
    "    val_metric=None,\n",
    "    tags=None,\n",
    "):\n",
    "\n",
    "    dir = f'./runs/{run_name}/'\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        filename=dir+'logging.log'   \n",
    "    )\n",
    "\n",
    "    print('hello')\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    total_steps = num_epochs * len(train_loader)\n",
    "    optim = optimizer(model.parameters(), lr=lr)\n",
    "    scheduler = get_scheduler(\n",
    "        name=lr_scheduler_type,\n",
    "        optimizer=optim,\n",
    "        num_training_steps=total_steps,\n",
    "        num_warmup_steps=warmup_steps\n",
    "    )\n",
    "\n",
    "    logging.info(f'Model: {model.name}, trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "    logging.info(f'Learning rate: {lr}, type: {lr_scheduler_type}')\n",
    "    logging.info(f'Epochs: {num_epochs}, total steps: {total_steps}')\n",
    "    logging.info(f'Dataset name: {dataset_name}')\n",
    "    logging.info(f'Train size: {len(train_loader)}, batch size: {train_batch_size}')\n",
    "\n",
    "    print('hi')\n",
    "\n",
    "    if val_dataset is not None:\n",
    "        val_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True)\n",
    "        val_steps = len(train_loader) if val_strategy == 'epoch' else len(train_loader) // 2\n",
    "        validation = []\n",
    "        metric = val_metric\n",
    "        logging.info(f'Validation size: {len(val_loader)}, batch size: {val_batch_size}')\n",
    "        logging.info(f'Evaluation metric: {metric.name}')\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    progress_bar, step = tqdm(range(total_steps)), 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs['loss']\n",
    "            loss.backward()\n",
    "\n",
    "            progress_bar.set_description(f'Training loss: {loss.item():0.5f}')\n",
    "            writer.add_scalar('train/loss', loss.item(), step)\n",
    "\n",
    "            if val_dataset is not None:\n",
    "                if (step + 1) % val_steps == 0:\n",
    "                    evalModel(model, val_loader, tags, metric, step, writer)\n",
    "\n",
    "                    torch.save(\n",
    "                        {\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optim.state_dict(),\n",
    "                            'loss': loss\n",
    "                        }, dir+f'{step}.pt'\n",
    "                    )\n",
    "\n",
    "                    model.train()\n",
    "\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "\n",
    "            writer.add_scalar('train/learning_rate', scheduler.get_last_lr()[0], step)\n",
    "            logging.info(f'Step: {step}, \\t training loss: {loss.item()}, \\t learning rate: {scheduler.get_last_lr()[0]}')\n",
    "            \n",
    "            step += 1\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'loss': loss\n",
    "        }, dir+f'{step}.pt'\n",
    "    )\n",
    "\n",
    "    return validation if val_dataset is not None else None\n",
    "\n",
    "''' MAIN TEST FUNCTION '''\n",
    "def testModel(model, set, metric, batch_size, tags=None):\n",
    "\n",
    "    test_loader = DataLoader(set, batch_size=batch_size)\n",
    "    task = model.task\n",
    "    model.eval()\n",
    "    \n",
    "    predicted, true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            labels = batch['labels']\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            predict = torch.argmax(outputs['predicts'], dim=-1)\n",
    "        \n",
    "            true.extend(labels.to('cpu'))\n",
    "            predicted.extend(predict.to('cpu'))\n",
    "\n",
    "    predicted, labels = torch.stack(predicted), torch.stack(true)\n",
    "\n",
    "    if task == 'classification':\n",
    "    \n",
    "        result = metric.compute(predictions=predicted, references=labels)\n",
    "        return result['accuracy']\n",
    "\n",
    "    if task == 'ner':\n",
    "\n",
    "        true_predictions = [\n",
    "            [tags[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predicted, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [tags[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predicted, labels)\n",
    "        ]\n",
    "    \n",
    "        results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "        return {\n",
    "            \"predictions\": predicted, \n",
    "            \"labels\": labels,\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Found cached dataset conll2003 (C:/Users/Даниил/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|██████████| 3/3 [00:00<00:00, 428.31it/s]\n",
      "Loading cached processed dataset at C:\\Users\\Даниил\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-7bbf9e07a61b75bc.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Даниил\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-89708a3a4bba9ab1.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Даниил\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-658553d0113f7fd6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conll2003/prajjwal1/bert-small\n",
      "hello\n",
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:27<00:00,  7.29it/s][04:53<05:23,  1.36it/s]\n",
      "100%|██████████| 204/204 [00:28<00:00,  7.27it/s][11:14<00:00,  1.35it/s]  \n",
      "Training loss: 0.06872: 100%|██████████| 878/878 [12:12<00:00,  1.20it/s]\n",
      "100%|██████████| 108/108 [00:30<00:00,  3.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 2,  ..., 2, 0, 0],\n",
       "         [0, 5, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[-100,    0,    0,  ..., -100, -100, -100],\n",
       "         [-100,    1, -100,  ..., -100, -100, -100],\n",
       "         [-100,    5, -100,  ..., -100, -100, -100],\n",
       "         ...,\n",
       "         [-100,    1,    0,  ..., -100, -100, -100],\n",
       "         [-100,    0,    0,  ..., -100, -100, -100],\n",
       "         [-100,    0,    0,  ..., -100, -100, -100]]),\n",
       " 'precision': 0.863201807752477,\n",
       " 'recall': 0.8792492917847026,\n",
       " 'f1': 0.8711516533637401,\n",
       " 'accuracy': 0.9738774631204911}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class Training():\n",
    "    def __init__(\n",
    "        self, \n",
    "        model,\n",
    "        task,\n",
    "        classes,\n",
    "        slice=100,\n",
    "        pretrained=True\n",
    "    ):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        \n",
    "        if task == 'classification':\n",
    "            self.model = EncoderForSequenceClassification(model, classes, pretrained=pretrained).to(device)\n",
    "            self.datasets = loadIMDB(self.tokenizer, slice)\n",
    "            self.dataset = 'imdb'\n",
    "            self.tags = None\n",
    "            self.metric = evaluate.load('accuracy')\n",
    "\n",
    "        if task == 'ner':\n",
    "            self.model = EncoderForTokenClassification(model, classes, pretrained=pretrained).to(device)\n",
    "            self.datasets = loadCONLL(self.tokenizer, slice)\n",
    "            self.dataset = 'conll2003'\n",
    "            self.tags = self.datasets['tags']\n",
    "            self.metric = evaluate.load('seqeval')\n",
    "        \n",
    "        self.run_name = self.dataset + '/' + model\n",
    "\n",
    "        if not pretrained:\n",
    "            self.run_name += '_random'\n",
    "\n",
    "model_name = [\n",
    "    'albert-base-v2',\n",
    "    'prajjwal1/bert-tiny',\n",
    "    'prajjwal1/bert-small'\n",
    "][2]\n",
    "\n",
    "training = Training(\n",
    "    model_name,\n",
    "    task='ner',\n",
    "    classes=9,\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "print(training.run_name)\n",
    "\n",
    "trainModel(\n",
    "    model=training.model, \n",
    "    run_name=training.run_name,\n",
    "    train_dataset=training.datasets['train'],\n",
    "    val_dataset=training.datasets['val'],\n",
    "    dataset_name=training.dataset,\n",
    "    val_metric=training.metric,\n",
    "    tags=training.tags,\n",
    "    train_batch_size=32,\n",
    "    val_batch_size=16,\n",
    "    num_epochs=2,\n",
    "    lr=3e-04,\n",
    ")\n",
    "\n",
    "testModel(\n",
    "    model=training.model,\n",
    "    set=training.datasets['test'],\n",
    "    batch_size=32,\n",
    "    metric=training.metric,\n",
    "    tags=training.tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e5df068846dd857fd8f6e2337ec975361106f93a8ad476be75c82b4dc19b61a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
